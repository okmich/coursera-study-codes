{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Direct Preference Optimization (DPO) Using Hugging Face**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **60** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large language models (LLMs) have revolutionized the field of natural language processing (NLP) by achieving remarkable performance in various tasks. However, it is challenging to align these models with human preferences. Therefore, the direct preference optimization (DPO) method comes in place which directly optimizes LLMs based models on user preferences, enhancing their alignment with human expectations. In this hands-on lab, you'll use the transformer reinforcement learning (trl) library from Hugging Face to implement DPO and fine-tune LLMs.\n",
    "\n",
    "The objective of this lab is to provide a practical understanding of the DPO method and its implementation using the trl library. \n",
    "\n",
    "By the end of this lab, you'll have hands-on experience in creating a data set formatted for DPO, implementing the optimization process, and evaluating the enhanced performance of LLMs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Installing-required-libraries\">Installing required libraries</a></li>\n",
    "            <li><a href=\"#Importing-required-libraries\">Importing required libraries</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Create-and-configure-the-model-and-tokenizer\">Create and configure the model and tokenizer</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Quantized-model-configuration-(Optional)\">Quantized model configuration (Optional)</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Preprocess-dataset\">Preprocess dataset</a></li>\n",
    "    <li><a href=\"#DPO-configuration\">DPO configuration</a></li>\n",
    "    <li><a href=\"#DPO-training\">DPO training</a></li>\n",
    "    <li><a href=\"#Exercise\">Exercise</a>\n",
    "</ol>\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab, you'll be able to: \n",
    "- Understand the fundamentals of DPO and how it is different from proximal policy optimization (PPO)\n",
    "- Set up an environment by installing and configuring necessary tools and libraries, such as trl library from Hugging Face\n",
    "- Prepare a suitable environment for running DPO experiments with LLMs\n",
    "- Create a data set for DPO\n",
    "- Understand the required format for data sets used in DPO\n",
    "- Create and preprocess a data set that includes user preferences\n",
    "- Implement DPO by following a step-by-step guideline using the trl library\n",
    "- Set training arguments, create a base quantized LoRA model, and train it using a DPO trainer\n",
    "- Evaluate the performance of the LLM before and after applying DPO\n",
    "- Analyze the impact of DPO on aligning the model with user preferences\n",
    "\n",
    "By the end of this hands-on lab, you will be equipped with the knowledge and skills needed to apply DPO for fine-tuning LLMs using the trl library. This will enable you to enhance LLMs' performance and user alignment in various NLP applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing required libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. You will need to run the following cell to install them.\n",
    "\n",
    "**Note:** In this lab, you don't have a pinned version to demonstrate the latest functionality, but you can always pin versions in your labs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.3.1 in /opt/conda/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from torch==2.3.1) (4.13.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/jupyterlab/.local/lib/python3.12/site-packages (from torch==2.3.1) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy->torch==2.3.1) (1.3.0)\n",
      "Requirement already satisfied: trl==0.11.4 in /home/jupyterlab/.local/lib/python3.12/site-packages (0.11.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from trl==0.11.4) (2.3.1)\n",
      "Requirement already satisfied: transformers>=4.40.0 in /opt/conda/lib/python3.12/site-packages (from trl==0.11.4) (4.45.2)\n",
      "Requirement already satisfied: accelerate in /home/jupyterlab/.local/lib/python3.12/site-packages (from trl==0.11.4) (1.6.0)\n",
      "Requirement already satisfied: datasets in /home/jupyterlab/.local/lib/python3.12/site-packages (from trl==0.11.4) (3.2.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/jupyterlab/.local/lib/python3.12/site-packages (from trl==0.11.4) (0.9.18)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.12/site-packages (from trl==0.11.4) (1.26.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (4.13.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/jupyterlab/.local/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.11.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl==0.11.4) (12.8.93)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/jupyterlab/.local/lib/python3.12/site-packages (from transformers>=4.40.0->trl==0.11.4) (0.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.40.0->trl==0.11.4) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.40.0->trl==0.11.4) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jupyterlab/.local/lib/python3.12/site-packages (from transformers>=4.40.0->trl==0.11.4) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers>=4.40.0->trl==0.11.4) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jupyterlab/.local/lib/python3.12/site-packages (from transformers>=4.40.0->trl==0.11.4) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.40.0->trl==0.11.4) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.40.0->trl==0.11.4) (4.67.1)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /home/jupyterlab/.local/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.11.4) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.11.4) (14.0.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/jupyterlab/.local/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.11.4) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.11.4) (4.4.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate->trl==0.11.4) (6.1.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from datasets->trl==0.11.4) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from datasets->trl==0.11.4) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/jupyterlab/.local/lib/python3.12/site-packages (from datasets->trl==0.11.4) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home/jupyterlab/.local/lib/python3.12/site-packages (from datasets->trl==0.11.4) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/jupyterlab/.local/lib/python3.12/site-packages (from datasets->trl==0.11.4) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.12/site-packages (from datasets->trl==0.11.4) (3.11.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.11.4) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.11.4) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.11.4) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.11.4) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.11.4) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.11.4) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.11.4) (1.18.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.40.0->trl==0.11.4) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.40.0->trl==0.11.4) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.40.0->trl==0.11.4) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.40.0->trl==0.11.4) (2024.12.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.4) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.4) (2.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.4.0->trl==0.11.4) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets->trl==0.11.4) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets->trl==0.11.4) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jupyterlab/.local/lib/python3.12/site-packages (from pandas->datasets->trl==0.11.4) (2025.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy->torch>=1.4.0->trl==0.11.4) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jupyterlab/.local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11.4) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.11.4) (1.17.0)\n",
      "Requirement already satisfied: peft==0.14.0 in /opt/conda/lib/python3.12/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from peft==0.14.0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from peft==0.14.0) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from peft==0.14.0) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from peft==0.14.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.12/site-packages (from peft==0.14.0) (2.3.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (from peft==0.14.0) (4.45.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from peft==0.14.0) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from peft==0.14.0) (1.6.0)\n",
      "Requirement already satisfied: safetensors in /home/jupyterlab/.local/lib/python3.12/site-packages (from peft==0.14.0) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from peft==0.14.0) (0.30.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.25.0->peft==0.14.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from huggingface-hub>=0.25.0->peft==0.14.0) (2024.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.25.0->peft==0.14.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jupyterlab/.local/lib/python3.12/site-packages (from huggingface-hub>=0.25.0->peft==0.14.0) (4.13.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.14.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.14.0) (12.8.93)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jupyterlab/.local/lib/python3.12/site-packages (from transformers->peft==0.14.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.12/site-packages (from transformers->peft==0.14.0) (0.20.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft==0.14.0) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.25.0->peft==0.14.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.25.0->peft==0.14.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.25.0->peft==0.14.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.25.0->peft==0.14.0) (2024.12.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy->torch>=1.13.0->peft==0.14.0) (1.3.0)\n",
      "Collecting matplotlib==3.9.0\n",
      "  Using cached matplotlib-3.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.0) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.0) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.0) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.0) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.0) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.0) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.9.0) (1.17.0)\n",
      "Using cached matplotlib-3.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Installing collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.10.0\n",
      "    Uninstalling matplotlib-3.10.0:\n",
      "      Successfully uninstalled matplotlib-3.10.0\n",
      "Successfully installed matplotlib-3.9.0\n",
      "Requirement already satisfied: pandas in /home/jupyterlab/.local/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jupyterlab/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy==1.26.0 in /opt/conda/lib/python3.12/site-packages (1.26.0)\n",
      "Requirement already satisfied: datasets==3.2.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from datasets==3.2.0) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from datasets==3.2.0) (1.26.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from datasets==3.2.0) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from datasets==3.2.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/jupyterlab/.local/lib/python3.12/site-packages (from datasets==3.2.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.12/site-packages (from datasets==3.2.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.12/site-packages (from datasets==3.2.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/jupyterlab/.local/lib/python3.12/site-packages (from datasets==3.2.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/jupyterlab/.local/lib/python3.12/site-packages (from datasets==3.2.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.12/site-packages (from datasets==3.2.0) (3.11.14)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from datasets==3.2.0) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from datasets==3.2.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from datasets==3.2.0) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jupyterlab/.local/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets==3.2.0) (4.13.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets==3.2.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets==3.2.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets==3.2.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets==3.2.0) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets==3.2.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets==3.2.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jupyterlab/.local/lib/python3.12/site-packages (from pandas->datasets==3.2.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.3.1\n",
    "!pip install --user trl==0.11.4 # for optimization training\n",
    "!pip install peft==0.14.0 # for creating LoRA architecture\n",
    "!pip install matplotlib==3.9.0 \n",
    "!pip install pandas\n",
    "!pip install numpy==1.26.0\n",
    "!pip install --user datasets==3.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.45.2 in /opt/conda/lib/python3.12/site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers==4.45.2) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/jupyterlab/.local/lib/python3.12/site-packages (from transformers==4.45.2) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers==4.45.2) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers==4.45.2) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers==4.45.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jupyterlab/.local/lib/python3.12/site-packages (from transformers==4.45.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers==4.45.2) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jupyterlab/.local/lib/python3.12/site-packages (from transformers==4.45.2) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.12/site-packages (from transformers==4.45.2) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers==4.45.2) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jupyterlab/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (4.13.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.45.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.45.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.45.2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.45.2) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.45.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user trl==0.11.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries\n",
    "\n",
    "_It's recommended to import all required libraries in one place (here):_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imports\n",
    "import multiprocessing\n",
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,TrainingArguments, GPT2Tokenizer, set_seed, GenerationConfig\n",
    "from trl import DPOConfig, DPOTrainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and configure the model and tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b34be25302b4cffb7250e410f809355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d5d94e70b644b4be3659a74fcf1c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3d09a4483e4bd0bfda71e92d12cf89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3790ae19ce24f2e867ef71623d4a306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64e003490f547909e5055a3e5c2340d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92977b04e204482f91b8845dea38afe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2daf3e297b9a49988d599d13a95a663e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load the GPT-2 model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load a reference model \n",
    "model_ref = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Set the pad token to the end-of-sequence token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# Set the padding side to \"right\" to fix the overflow issue with FP16 training\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Disable the use of the cache during the model's forward pass\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can check the model architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantized model configuration (Optional)\n",
    "If you want memory-efficient training and have access to a GPU-powered environment, you can download the complete lab, uncomment the following two code blocks to create a quantized model and proceed with training the model on GPU. This is because you will need GPUs for the bits and bytes package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U bitsandbytes # this package is required for quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Note:_**  _You can run the installed package by restarting a Kernel._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Quantized model --only available on GPU\\nfrom transformers import BitsAndBytesConfig\\n\\n# Configure the quantization parameters\\nquantization_config = BitsAndBytesConfig(\\n    # Load the model in 4-bit quantized format\\n    load_in_4bit=True,\\n    # Enable double quantization for better accuracy\\n    bnb_4bit_use_double_quant=True,\\n    # Use non-uniform 4-bit quantization (nf4)\\n    bnb_4bit_quant_type=\"nf4\",\\n    # Use bfloat16 as the computation data type during quantization\\n    bnb_4bit_compute_dtype=torch.bfloat16\\n)\\n\\n# Load GPT-2 model with the specified quantization configuration\\nmodel = AutoModelForCausalLM.from_pretrained(\"gpt2\", quantization_config=quantization_config)\\n\\n# Load a reference model with the same quantization configuration\\nmodel_ref = AutoModelForCausalLM.from_pretrained(\"gpt2\", quantization_config=quantization_config)\\n\\n# Load GPT-2 tokenizer\\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\\n\\n# Set the pad token to the end-of-sequence token\\ntokenizer.pad_token = tokenizer.eos_token\\n# Set the padding side to \"right\" to fix the overflow issue with FP16 training\\ntokenizer.padding_side = \"right\"\\n\\n# Disable the use of the cache during the model\\'s forward pass\\nmodel.config.use_cache = False'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''## Quantized model --only available on GPU\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Configure the quantization parameters\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    # Load the model in 4-bit quantized format\n",
    "    load_in_4bit=True,\n",
    "    # Enable double quantization for better accuracy\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    # Use non-uniform 4-bit quantization (nf4)\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    # Use bfloat16 as the computation data type during quantization\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load GPT-2 model with the specified quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", quantization_config=quantization_config)\n",
    "\n",
    "# Load a reference model with the same quantization configuration\n",
    "model_ref = AutoModelForCausalLM.from_pretrained(\"gpt2\", quantization_config=quantization_config)\n",
    "\n",
    "# Load GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Set the pad token to the end-of-sequence token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# Set the padding side to \"right\" to fix the overflow issue with FP16 training\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Disable the use of the cache during the model's forward pass\n",
    "model.config.use_cache = False'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data set\n",
    "\n",
    "The \"ultrafeedback_binarized\" data set on Hugging Face is a collection of prompts and responses.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da96f2b7a37241fc999039ae1756d3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7338c1e8f2f46a09b80ad78165474b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_prefs-00000-of-00001.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bab018690944af91a59fb726b60a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_prefs-00000-of-00001.parquet:   0%|          | 0.00/7.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4969b746b864f33bd8d455d7f44f1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_sft-00000-of-00001.parquet:   0%|          | 0.00/3.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c490ab788e5479ebbcd55bcd61a71fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_gen-00000-of-00001.parquet:   0%|          | 0.00/184M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9bdf6cdd6d4b91ba991e99fe4492e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_gen-00000-of-00001.parquet:   0%|          | 0.00/3.02M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de5d06804664ecc999a1e3925d610cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_prefs split:   0%|          | 0/61135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c522b365da7d44b8b00b2456bea724d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_sft split:   0%|          | 0/61135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3907d47fb16d4948a903afdff897bf87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_prefs split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0633c71612884d9096b2b55080889e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_sft split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbe63c9747b495a93d00015f8f3cedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_gen split:   0%|          | 0/61135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b5028931734f74af91603544cd492c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_gen split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset from the specified location\n",
    "ds = load_dataset(\"BarraHome/ultrafeedback_binarized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set includes six splits. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_prefs', 'train_sft', 'test_prefs', 'test_sft', 'train_gen', 'test_gen'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each record has different features among which you need to select from the three features, that is \"chosen,\" \"rejected,\" and \"prompt.\" This means that for each prompt, a prefered response and a rejected response are provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train_prefs\"][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the sample record of data, where you can see three features along with other features that is the prompt, the rejected, and chosen responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'how can i develop a habit of drawing daily',\n",
       " 'prompt_id': '086b3e24f29b8956a01059f79c56db35d118a06fb6b844b095737d042795cd43',\n",
       " 'chosen': [{'content': 'how can i develop a habit of drawing daily',\n",
       "   'role': 'user'},\n",
       "  {'content': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
       "   'role': 'assistant'}],\n",
       " 'rejected': [{'content': 'how can i develop a habit of drawing daily',\n",
       "   'role': 'user'},\n",
       "  {'content': \"One way to develop a habit of drawing daily is to allocate a specific time interval for drawing each day, whether it's early in the morning or before going to bed at night. You can also find inspiration or motivation to draw by joining drawing communities, following artists on social media, or going out into nature and sketching what you see. Additionally, practicing drawing every day can help you improve your skills over time.\",\n",
       "   'role': 'assistant'}],\n",
       " 'messages': [{'content': 'how can i develop a habit of drawing daily',\n",
       "   'role': 'user'},\n",
       "  {'content': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
       "   'role': 'assistant'}],\n",
       " 'score_chosen': 8.5,\n",
       " 'score_rejected': 7.5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train_prefs\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, put the data set in the format that the DPO trainer accepts.\n",
    "\n",
    "| Chosen | Rejected | Prompt |\n",
    "| --- | --- | --- |\n",
    " | Developing a daily habit of drawing can be challenging <br>but with consistent practice, and a few tips. | One way to develop a habit of drawing daily is <br>to allocate a specific time interval for drawing. | How can I develop a habit of drawing daily?|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150ce7aa461a4875afb8bff87dce0064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132f06423ad34e52a3fde22984d14344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5af1cf884f94ba5b85a32a7e3efe285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4abefd6b9a4e4fa042212b79c177bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc2bbb5b7b74fd98950afac693fcf53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a24fd2ed964ef9a25911bfc1ced54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can reduce the volume of data (due to resource limitations) by selecting the first 5% examples from each split of the dataset\n",
    "for key in ds:\n",
    "    #cnt = round(ds[key].__len__()*0.05)\n",
    "    cnt=50\n",
    "    ds[key] = ds[key].select(range(cnt))\n",
    "\n",
    "# Define a function to process the data\n",
    "def process(row):\n",
    "    # delete unwanted columns\n",
    "    del row[\"prompt_id\"]\n",
    "    del row[\"messages\"]\n",
    "    del row[\"score_chosen\"]\n",
    "    del row[\"score_rejected\"]\n",
    "    # retrieve the actual response text\n",
    "    row[\"chosen\"] = row[\"chosen\"][-1][\"content\"]\n",
    "    row[\"rejected\"] = row[\"rejected\"][-1][\"content\"]\n",
    "\n",
    "    return row\n",
    "\n",
    "# Apply the data processing function to the dataset\n",
    "ds = ds.map(\n",
    "    process,\n",
    "    num_proc=multiprocessing.cpu_count(),\n",
    "    load_from_cache_file=False,\n",
    ")\n",
    "\n",
    "# Split the dataset into training and evaluation sets\n",
    "train_dataset = ds['train_prefs']\n",
    "eval_dataset = ds['test_prefs']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the data record.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'how can i develop a habit of drawing daily',\n",
       " 'chosen': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
       " 'rejected': \"One way to develop a habit of drawing daily is to allocate a specific time interval for drawing each day, whether it's early in the morning or before going to bed at night. You can also find inspiration or motivation to draw by joining drawing communities, following artists on social media, or going out into nature and sketching what you see. Additionally, practicing drawing every day can help you improve your skills over time.\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define LoRAConfig for efficient fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEFT (Parameter-Efficient Finetuning) configuration\n",
    "peft_config = LoraConfig(\n",
    "        # The rank of the low-rank adaptation weights\n",
    "        r=4,\n",
    "        # The target modules to apply the low-rank adaptation to\n",
    "        target_modules=['c_proj','c_attn'],\n",
    "        # The task type for the low-rank adaptation\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        # The scaling factor for the low-rank adaptation weights\n",
    "        lora_alpha=8,\n",
    "        # The dropout probability for the low-rank adaptation weights\n",
    "        lora_dropout=0.1,\n",
    "        # The bias mode for the low-rank adaptation\n",
    "        bias=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPO configuration\n",
    "\n",
    "First, define training arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# DPO configuration\n",
    "from peft import get_peft_model\n",
    "training_args = DPOConfig(\n",
    "    # The beta parameter for the DPO loss function\n",
    "    #beta is the temperature parameter for the DPO loss, typically something in the range of 0.1 to 0.5 . \n",
    "    beta=0.1,\n",
    "    # The output directory for the training\n",
    "    output_dir=\"dpo\",\n",
    "    # The number of training epochs\n",
    "    num_train_epochs=5,\n",
    "    # The batch size per device during training\n",
    "    per_device_train_batch_size=1,\n",
    "    # The batch size per device during evaluation\n",
    "    per_device_eval_batch_size=1,\n",
    "    # Whether to remove unused columns from the dataset\n",
    "    remove_unused_columns=False,\n",
    "    # The number of steps between logging training progress\n",
    "    logging_steps=10,\n",
    "    # The number of gradient accumulation steps\n",
    "    gradient_accumulation_steps=1,\n",
    "    # The learning rate for the optimization\n",
    "    learning_rate=1e-4,\n",
    "    # The evaluation strategy (e.g., after each step or epoch)\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    # The number of warmup steps for the learning rate scheduler\n",
    "    warmup_steps=2,\n",
    "    # Whether to use 16-bit (float16) precision\n",
    "    fp16=False,\n",
    "    # The number of steps between saving checkpoints\n",
    "    save_steps=500,\n",
    "    # The maximum number of checkpoints to keep\n",
    "    #save_total_limit=2,\n",
    "    # The reporting backend to use (set to 'none' to disable, you can also report to wandb or tensorboard)\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPO training\n",
    "\n",
    "Next step is creating the actual trainer using DPOTrainer class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/.local/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in DPOTrainer, please use the DPOConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.12/site-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "/home/jupyterlab/.local/lib/python3.12/site-packages/trl/trainer/dpo_trainer.py:655: UserWarning: You passed `max_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
      "  warnings.warn(\n",
      "/home/jupyterlab/.local/lib/python3.12/site-packages/trl/trainer/dpo_trainer.py:673: UserWarning: `max_prompt_length` is not set in the DPOConfig's init it will default to `128` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0899d5896c814668bdaecfb962aaa5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2d9c2265fd4696a4b24766294d2315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Create a DPO trainer\n",
    "# This trainer will handle the fine-tuning of the model using the DPO technique\n",
    "trainer = DPOTrainer(\n",
    "        # The model to be fine-tuned\n",
    "        model=model,\n",
    "        # The reference model (not used in this case because LoRA has been used)\n",
    "        ref_model=None,\n",
    "        # The DPO training configuration\n",
    "        args=training_args,\n",
    "        # The beta parameter for the DPO loss function\n",
    "       \n",
    "        # The training dataset\n",
    "        train_dataset=train_dataset,\n",
    "        # The evaluation dataset\n",
    "        eval_dataset=eval_dataset,\n",
    "        # The tokenizer for the model\n",
    "        tokenizer=tokenizer,\n",
    "        # The PEFT (Parallel Efficient Finetuning) configuration\n",
    "        peft_config=peft_config,\n",
    "        # The maximum prompt length\n",
    "        #max_prompt_length=512,\n",
    "        # The maximum sequence length\n",
    "        max_length=512,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that when using LoRA for the base model, it's efficient to leave the model_ref param null, in which case the DPOTrainer will unload the adapter for reference inference.\n",
    "\n",
    "\n",
    "Now, you're all set for training the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keep in mind that training the model on a CPU can be time-consuming and may cause the kernel to crash due to memory issues. If this happens, you can bypass training by loading the pre-trained model provided in the next section and proceed from there.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='99' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 99/250 37:28 < 58:20, 0.04 it/s, Epoch 1.96/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>0.672069</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.056960</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.047488</td>\n",
       "      <td>-528.023132</td>\n",
       "      <td>-536.362183</td>\n",
       "      <td>-103.791756</td>\n",
       "      <td>-103.799461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start the training process\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/trainer.py:2388\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/trainer.py:3485\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3485\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3490\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3491\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/trl/trainer/dpo_trainer.py:1489\u001b[0m, in \u001b[0;36mDPOTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1487\u001b[0m compute_loss_context_manager \u001b[38;5;241m=\u001b[39m amp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_peft_has_been_casted_to_bf16 \u001b[38;5;28;01melse\u001b[39;00m nullcontext()\n\u001b[1;32m   1488\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compute_loss_context_manager:\n\u001b[0;32m-> 1489\u001b[0m     loss, metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_loss_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;66;03m# Make sure to move the loss to the device the original accumulating loss is at back in the `Trainer` class:\u001b[39;00m\n\u001b[1;32m   1492\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/trl/trainer/dpo_trainer.py:1415\u001b[0m, in \u001b[0;36mDPOTrainer.get_batch_loss_metrics\u001b[0;34m(self, model, batch, train_eval)\u001b[0m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the DPO loss and other metrics for the given batch of inputs for train or test.\"\"\"\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1415\u001b[0m forward_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenated_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1416\u001b[0m (\n\u001b[1;32m   1417\u001b[0m     policy_chosen_logps,\n\u001b[1;32m   1418\u001b[0m     policy_rejected_logps,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1421\u001b[0m     policy_nll_loss,\n\u001b[1;32m   1422\u001b[0m ) \u001b[38;5;241m=\u001b[39m forward_output[:\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maux_loss_enabled:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/trl/trainer/dpo_trainer.py:1354\u001b[0m, in \u001b[0;36mDPOTrainer.concatenated_forward\u001b[0;34m(self, model, batch)\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maux_loss_enabled:\n\u001b[1;32m   1352\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_router_logits\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1354\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcatenated_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconcatenated_input_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcatenated_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconcatenated_attention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m all_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_logits\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m!=\u001b[39m concatenated_batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcatenated_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m   1363\u001b[0m     \u001b[38;5;66;03m# for llava, the model returns logits for the entire sequence, including the image tokens (placed before the text tokens)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/peft/peft_model.py:1719\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1718\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1719\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1732\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1316\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1316\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1130\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1119\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1120\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1127\u001b[0m         output_attentions,\n\u001b[1;32m   1128\u001b[0m     )\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1141\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:615\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    613\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    614\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 615\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    624\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:518\u001b[0m, in \u001b[0;36mGPT2SdpaAttention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    516\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m encoder_attention_mask\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m     query, key, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_size, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    520\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(query, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    521\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/peft/tuners/lora/layer.py:609\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_layer(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     torch_result_dtype \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m active_adapter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_adapters:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/pytorch_utils.py:111\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    110\u001b[0m     size_out \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnf,)\n\u001b[0;32m--> 111\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddmm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(size_out)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start the training process\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown option --v\n",
      "usage: python [option] ... [-c cmd | -m mod | file | -] [arg] ...\n",
      "Try `python -h' for more information.\n"
     ]
    }
   ],
   "source": [
    "!python --v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(hasattr(model, \"generate\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve and plot the training loss versus evaluation loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieve log_history and save it to a dataframe\n",
    "log = pd.DataFrame(trainer.state.log_history)\n",
    "log_t = log[log['loss'].notna()]\n",
    "log_e = log[log['eval_loss'].notna()]\n",
    "\n",
    "# Plot train and evaluation losses\n",
    "plt.plot(log_t[\"epoch\"], log_t[\"loss\"], label = \"train_loss\") \n",
    "plt.plot(log_e[\"epoch\"], log_e[\"eval_loss\"], label = \"eval_loss\") \n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/7KEnvtpUyNcJTINdArLf7A/loss%20dpo.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: './dpo/checkpoint-250'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:154\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './dpo/checkpoint-250'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the trained DPO model you just trained\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dpo_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./dpo/checkpoint-250\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:487\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m--> 487\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/utils/hub.py:469\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 469\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    471\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: './dpo/checkpoint-250'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "# Load the trained DPO model you just trained\n",
    "dpo_model = AutoModelForCausalLM.from_pretrained('./dpo/checkpoint-250')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you encounter difficulty in running the training cell due to resource limitations, you can download the model to be fine-tuned: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_520/2720268774.py:15: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted: ['DPO', 'DPO/adapter_config.json', 'DPO/tokenizer_config.json', 'DPO/merges.txt', 'DPO/adapter_model.safetensors', 'DPO/special_tokens_map.json', 'DPO/training_args.bin', 'DPO/README.md', 'DPO/vocab.json']\n"
     ]
    }
   ],
   "source": [
    "# Define the URL and the filename\n",
    "url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/YIDeT3qihEpWChdXN_RmTg/DPO-tar.gz'\n",
    "filename = './DPO.tar'\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "\n",
    "# Save the file locally\n",
    "with open(filename, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Extract the tar file\n",
    "if tarfile.is_tarfile(filename):\n",
    "    with tarfile.open(filename, 'r') as tar:\n",
    "        tar.extractall()\n",
    "        print(\"Files extracted:\", tar.getnames())\n",
    "else:\n",
    "    print(\"The adownloaded file is not a tar file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, load it into the model for further inference:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained DPO model tiy just trained\n",
    "dpo_model = AutoModelForCausalLM.from_pretrained('./DPO')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPO response:\t Is a higher octane gasoline better for your car?\n",
      "\n",
      "The answer is yes. The higher octane gasoline is better for your car.\n",
      "\n",
      "The higher octane gasoline\n",
      "\n",
      "GPT2 response:\t Is a higher octane gasoline better for your car?\n",
      "\n",
      "The answer is yes. The higher octane gasoline is more efficient and more fuel efficient.\n",
      "\n",
      "The higher oct\n"
     ]
    }
   ],
   "source": [
    "# Set a seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "\n",
    "# Define the generation configuration for the DPO model\n",
    "# This sets the parameters for text generation\n",
    "generation_config = GenerationConfig(\n",
    "        # Use sampling to generate diverse text\n",
    "        do_sample=True,\n",
    "        # Top-k sampling parameter\n",
    "        top_k=1,\n",
    "        # Temperature parameter to control the randomness of the generated text\n",
    "        temperature=0.1,\n",
    "        # Maximum number of new tokens to generate\n",
    "        max_new_tokens=25,\n",
    "        # Use the end-of-sequence token as the padding token\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# Define the input prompt for text generation\n",
    "PROMPT = \"Is a higher octane gasoline better for your car?\"\n",
    "# Encode the prompt using the tokenizer\n",
    "inputs = tokenizer(PROMPT, return_tensors='pt')\n",
    "\n",
    "# Generate text using the DPO model\n",
    "outputs = dpo_model.generate(**inputs, generation_config=generation_config)\n",
    "# Decode the generated text and print it\n",
    "print(\"DPO response:\\t\",tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "# Load the pre-trained GPT-2 model\n",
    "gpt2_model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "# Generate text using the GPT-2 model\n",
    "outputs = gpt2_model.generate(**inputs, generation_config=generation_config)\n",
    "# Decode the generated text and print it\n",
    "print(\"\\nGPT2 response:\\t\",tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Althought the model is trained on a small data for 5 epochs only, it can be seen that the response generated by the DPO-tuned model is more concise and straightforward.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Preprocess the `argilla/ultrafeedback-binarized-preferences-cleaned` Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set comprises user-generated prompts along with corresponding responses categorized as either \"chosen\" or \"rejected.\" It provides a rich source of binary feedback, making it ideal for training models to align with user preferences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the data set from the `argilla/ultrafeedback-binarized-preferences-cleaned`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd266169d6234e8eb61da0b97a7c63dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e520932c81184d3fb7f9ffc22aaf794f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/143M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3474ac1f4c4bb5afd530f8e86ed6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/60917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO\n",
    "dataset = load_dataset(\"argilla/ultrafeedback-binarized-preferences-cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for hint</summary>\n",
    "\n",
    "```python\n",
    "dataset = load_dataset(\"argilla/ultrafeedback-binarized-preferences-cleaned\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'prompt', 'chosen', 'chosen-rating', 'chosen-model', 'rejected', 'rejected-rating', 'rejected-model'],\n",
       "    num_rows: 60917\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set the variable cnt to 50 and then select the first 50 (cnt) examples to reduce the volume of data for resource limitations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "cnt = 50  # You can adjust this count based on your requirements\n",
    "\n",
    "# Select the first 5% of examples\n",
    "dataset['train'] = dataset['train'].select(range(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for hint</summary>\n",
    "\n",
    "```python\n",
    "cnt = 50  # You can adjust this count based on your requirements\n",
    "\n",
    "# Select the first 5% of examples\n",
    "dataset['train'] = dataset['train'].select(range(cnt))\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a function named `process` that takes a row of data as input. Within this function, remove unwanted columns such as `source, chosen-rating, chosen-model, rejected-rating, and rejected-model`. Then, use the map function to apply the process function to each row in the training data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4d1fb7b225490abe7c52d3524a6a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "def process(row):\n",
    "    # Delete unwanted columns\n",
    "    del row[\"source\"]\n",
    "    del row[\"chosen-rating\"]\n",
    "    del row[\"chosen-model\"]\n",
    "    del row[\"rejected-rating\"]\n",
    "    del row[\"rejected-model\"]\n",
    "    \n",
    "    # Retrieve the actual response text\n",
    "    row[\"chosen\"] = row[\"chosen\"][-1][\"content\"]\n",
    "    row[\"rejected\"] = row[\"rejected\"][-1][\"content\"]\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Apply the data processing function to the dataset\n",
    "dataset['train'] = dataset['train'].map(\n",
    "    process,\n",
    "    num_proc=multiprocessing.cpu_count(),\n",
    "    load_from_cache_file=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for hint</summary>\n",
    "\n",
    "```python\n",
    "def process(row):\n",
    "    # Delete unwanted columns\n",
    "    del row[\"source\"]\n",
    "    del row[\"chosen-rating\"]\n",
    "    del row[\"chosen-model\"]\n",
    "    del row[\"rejected-rating\"]\n",
    "    del row[\"rejected-model\"]\n",
    "    \n",
    "    # Retrieve the actual response text\n",
    "    row[\"chosen\"] = row[\"chosen\"][-1][\"content\"]\n",
    "    row[\"rejected\"] = row[\"rejected\"][-1][\"content\"]\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Apply the data processing function to the dataset\n",
    "dataset['train'] = dataset['train'].map(\n",
    "    process,\n",
    "    num_proc=multiprocessing.cpu_count(),\n",
    "    load_from_cache_file=False,\n",
    ")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the data set into training and evaluation sets:\n",
    "Calculate the size for the training set as 80% of the total data. The remaining 20% will be used for evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "train_size = int(0.8 * len(dataset['train']))  # 80% for training\n",
    "eval_size = len(dataset['train']) - train_size  # Remaining 20% for evaluation\n",
    "\n",
    "train_dataset = dataset['train'].select(range(train_size))\n",
    "eval_dataset = dataset['train'].select(range(train_size, train_size + eval_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for hint</summary>\n",
    "\n",
    "```python\n",
    "train_size = int(0.8 * len(dataset['train']))  # 80% for training\n",
    "eval_size = len(dataset['train']) - train_size  # Remaining 20% for evaluation\n",
    "\n",
    "train_dataset = dataset['train'].select(range(train_size))\n",
    "eval_dataset = dataset['train'].select(range(train_size, train_size + eval_size))\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 40\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Can you write a C++ program that prompts the user to enter the name of a country and checks if it borders the Mediterranean Sea? Here\\'s some starter code to help you out:\\n#include <iostream>\\n#include <string>\\nusing namespace std;\\nint main() {\\n    string country;\\n    // prompt user for input\\n    cout << \"Enter the name of a country: \";\\n    cin >> country;\\n    // check if country borders the Mediterranean Sea\\n    // [C++ code]\\n    return 0;\\n}',\n",
       " 'chosen': 'Here\\'s a C++ program that prompts the user to enter the name of a country and checks if it borders the Mediterranean Sea:\\n\\n#include <iostream>\\n#include <string>\\n#include <set>\\n#include <map>\\n#include <algorithm>\\n\\nusing namespace std;\\n\\nint main() {\\n    // store countries and their bordering seas in a map\\n    map<string, set<string>> countries;\\n    countries[\"Algeria\"] = {\"Mediterranean Sea\", \"North African Coast\"};\\n    countries[\"France\"] = {\"Mediterranean Sea\", \"English Channel\"};\\n    countries[\"Italy\"] = {\"Mediterranean Sea\", \"Adriatic Sea\"};\\n    countries[\"Malta\"] = {\"Mediterranean Sea\", \"North African Coast\"};\\n    countries[\"Spain\"] = {\"Mediterranean Sea\", \"Atlantic Ocean\"};\\n    countries[\"Tunisia\"] = {\"Mediterranean Sea\", \"North African Coast\"};\\n\\n    string country;\\n    cout << \"Enter the name of a country: \";\\n    cin >> country;\\n\\n    // check if country is in the map\\n    if (countries.find(country)!= countries.end()) {\\n        // check if country borders the Mediterranean Sea\\n        set<string> borders = countries.at(country);\\n        if (borders.find(\"Mediterranean Sea\")!= borders.end()) {\\n            cout << country << \" borders the Mediterranean Sea.\" << endl;\\n        } else {\\n            cout << country << \" does not border the Mediterranean Sea.\" << endl;\\n        }\\n    } else {\\n        cout << country << \" is not a recognized country.\" << endl;\\n    }\\n\\n    return 0;\\n}\\n\\nIn this program, we first define a map called countries that stores each country\\'s name as a key and a set of its surrounding seas as the value. We use a set to store each sea name so that we can easily check if a country borders a certain sea.\\n\\nWe then present the user with a prompt to enter the name of a country. We use a while loop to ensure that the user enters a valid country name. We check if the country is in the map, and if so, we retrieve its bordering seas from the map.\\n\\nFinally, we check if the Mediterranean Sea is among the set of borders. If it is, we inform the user that the country borders the Mediterranean Sea. If not, we inform the user that the country does not border the Mediterranean Sea.',\n",
       " 'rejected': 'Sure, here is the program using the C++11 algorithm \"cds::algorithm::GreaterEqual\":\\n#include <iostream>\\n#include <string>\\n#include <algorithm>\\n#include <vector>\\n#include <cctype>\\n\\nusing namespace std;\\n\\nint main() {\\n    string country;\\n    cout << \"Enter the name of a country: \";\\n    cin >> country;\\n    std::vector<string> vec;\\n    vec.push_back(country);\\n    size_t index = std::find_if(vec.begin(), vec.end(), [](const string& s) {\\n        return std::any_of(s.begin(), s.end(), [](const char& c) {\\n            return c == \\'}}\\';\\n    });\\n    if (index != vec.end()) {\\n        if ((*index)[0] == \\'M\\') {\\n            cout << \"Country is bordered by the Mediterranean Sea.\" << endl;\\n        } else {\\n            cout << \"Country does not border the Mediterranean Sea.\" << endl;\\n        }\\n    } else {\\n        cout << \"Country is not found.\" << endl;\\n    }\\n    return 0;\\n}'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Prompt Inferencing and Comparison with GPT-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " What is the capital of Nigeria?\n"
     ]
    }
   ],
   "source": [
    "PROMPT = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize the GPT-2 Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for hint</summary>\n",
    "\n",
    "```python\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a generation_config object to set the parameters for text generation.\n",
    "- do_sample=True    (It enables sampling, which allows for more diverse outputs.)\n",
    "- top_k=1 (It specifies the number of highest probability vocabulary tokens to consider during generation.)\n",
    "- temperature=0.1 (It controls the randomness of the output.)\n",
    "- max_new_tokens=25 (It sets the maximum number of new tokens to generate during inference.)\n",
    "- pad_token_id=tokenizer.eos_token_id (It specifies the token to use for padding.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "generation_config = GenerationConfig(\n",
    "    # Use sampling to generate diverse text\n",
    "    do_sample=True,\n",
    "    # Top-k sampling parameter: controls the number of highest probability tokens to consider\n",
    "    top_k=1,\n",
    "    # Temperature parameter: controls the randomness of the generated text\n",
    "    temperature=0.1,\n",
    "    # Maximum number of new tokens to generate\n",
    "    max_new_tokens=25,\n",
    "    # Use the end-of-sequence token as the padding token\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for hint</summary>\n",
    "\n",
    "```python\n",
    "generation_config = GenerationConfig(\n",
    "    # Use sampling to generate diverse text\n",
    "    do_sample=True,\n",
    "    # Top-k sampling parameter: controls the number of highest probability tokens to consider\n",
    "    top_k=1,\n",
    "    # Temperature parameter: controls the randomness of the generated text\n",
    "    temperature=0.1,\n",
    "    # Maximum number of new tokens to generate\n",
    "    max_new_tokens=25,\n",
    "    # Use the end-of-sequence token as the padding token\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a function named `generate_dpo_response` that takes a prompt as input and generates a response using the DPO model (`dpo_model`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "def generate_dpo_response(prompt):\n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "\n",
    "    # Generate text using the DPO model\n",
    "    outputs = dpo_model.generate(**inputs, generation_config=generation_config)\n",
    "    \n",
    "    # Decode and return the response\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for hint</summary>\n",
    "\n",
    "```python\n",
    "def generate_dpo_response(prompt):\n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "\n",
    "    # Generate text using the DPO model\n",
    "    outputs = dpo_model.generate(**inputs, generation_config=generation_config)\n",
    "    \n",
    "    # Decode and return the response\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create another function named `generate_gpt2_response` that takes a prompt as input and generates a response using the GPT-2 model (`gpt2_model`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "def generate_gpt2_response(prompt):\n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "\n",
    "    # Generate text using the GPT-2 model\n",
    "    outputs = gpt2_model.generate(**inputs, generation_config=generation_config)\n",
    "    \n",
    "    # Decode and return the response\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for hint</summary>\n",
    "\n",
    "```python\n",
    "def generate_gpt2_response(prompt):\n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "\n",
    "    # Generate text using the GPT-2 model\n",
    "    outputs = gpt2_model.generate(**inputs, generation_config=generation_config)\n",
    "    \n",
    "    # Decode and return the response\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Call both functions with a prompt and compare the responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPO response:\t What is the capital of Nigeria?\n",
      "\n",
      "The capital of Nigeria is the capital of the country. It is the capital of the country. It is the capital\n",
      "\n",
      "GPT-2 response:\t What is the capital of Nigeria?\n",
      "\n",
      "The capital of Nigeria is the capital of the country. It is the capital of the country. It is the capital\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "dpo_response = generate_dpo_response(PROMPT)\n",
    "gpt2_response = generate_gpt2_response(PROMPT)\n",
    "\n",
    "# Print the responses\n",
    "print(\"DPO response:\\t\", dpo_response)\n",
    "print(\"\\nGPT-2 response:\\t\", gpt2_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Click here for hint</summary>\n",
    "\n",
    "```python\n",
    "# Generate responses\n",
    "dpo_response = generate_dpo_response(PROMPT)\n",
    "gpt2_response = generate_gpt2_response(PROMPT)\n",
    "\n",
    "# Print the responses\n",
    "print(\"DPO response:\\t\", dpo_response)\n",
    "print(\"\\nGPT-2 response:\\t\", gpt2_response)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations! You have completed the lab!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fateme Akbari](https://www.linkedin.com/in/fatemeakbari/) is a Ph.D. candidate in Information Systems at McMaster University with demonstrated research experience in Machine Learning and NLP.\n",
    "\n",
    "[Kunal Makwana](https://author.skills.network/instructors/kunal_makwana) is a Data Scientist at IBM and is currently pursuing his Master's in Computer Science at Dalhousie University.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[DPO Trainer](https://huggingface.co/docs/trl/main/en/dpo_trainer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© Copyright IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "1423db1b9601de50ab6ef871a2b0ccf668561a79fd2c376658de979b10985706"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
